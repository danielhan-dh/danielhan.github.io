<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Homework 2</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 0;
            background-color: #f7f7f7;
        }
        .container {
            width: 80%;
            background-color: #fff;
            padding: 20px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
            text-align: center;
        }
        h1, h2 {
            margin-bottom: 10px;
        }
        .code-block {
            background-color: #f1f1f1;
            border-radius: 8px;
            padding: 20px;
            text-align: left;
            font-family: "Courier New", Courier, monospace;
            white-space: pre-wrap;
            word-wrap: break-word;
            margin-bottom: 20px;
        }
        .code-block code {
            color: #d63384;
        }
        p {
            text-align: justify;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>Homework 2</h1>
        <h2>Question 1</h2>
        <p>Presented below is code of gradient boosting on a locally weighted regression algorithm. This code is then applied onto the dataset "concrete" which contains various feature variables detailing the attributes of concrete. These feature variables are then used to train and predict the y value "strength".</p>

        <div class="code-block">
            <code>
                def loess(xtrain, ytrain, kern, tau, scalerType, alpha):<br>
                    distances = cdist(xtrain, xtrain, metric='Euclidean')<br>
                    scaler = scalerType<br>
                    xscaled = scaler.fit_transform(xtrain)<br>
                    weights = kernel_function(distances, kern, tau=0.05)<br>
                    model = Ridge(alpha=alpha, max_iter=5000)<br>
                    models = []<br>
                    predictions = []<br>
                    for i in range(len(xtrain)):<br>
                        loess = model.fit(np.diag(weights[:, i]) @ xscaled, np.diag(weights[:, i]) @ ytrain)<br>
                        predictions[i] = models[i].predict(X[i].reshape(1, -1))<br>
                        models.append(loess)<br>
                    return models, weights, scaler, predictions
            </code>
        </div>

        <p>Here is the code for the loess model created in homework 1. In this method, it scales the data and computes the distances to fit the loess model.</p>

        <h2>Implementation of Gradient Boosting</h2>
        <p>Below is the implementation of the gradient boosting into the loess model. This includes the methods <code>fit</code>, <code>is_fitted</code>, and <code>predict</code>, as well as the method <code>cross_validate</code> to cross-validate the data at the end.</p>

        <div class="code-block">
            <code>
                class LOESS:<br>
                    def __init__(self, kern='tricube', tau=0.05, alpha=0.01, scalerType=StandardScaler()):<br>
                        self.kern = kern<br>
                        self.tau = tau<br>
                        self.alpha = alpha<br>
                        self.scalerType = scalerType<br>
                        self.is_fitted_ = False  # To track if the model has been fitted<br>
                        self.models = []<br>
                        self.scaler = None<br>
                    <br>
                    def fit(self, X, y, boosting_steps=10):<br>
                        self.scaler = self.scalerType<br>
                        X_scaled = self.scaler.fit_transform(X)<br>
                        residuals = y.copy()<br>
                        for step in range(boosting_steps):<br>
                            distances = cdist(X_scaled, X_scaled, metric='euclidean')<br>
                            weights = kernel_function(distances, self.kern, tau=self.tau)<br>
                            model = Ridge(alpha=self.alpha, max_iter=5000)<br>
                            predictions = np.zeros(len(X_scaled))<br>
                            for i in range(len(X_scaled)):<br>
                                loess_model = model.fit(np.diag(weights[:, i]) @ X_scaled, np.diag(weights[:, i]) @ residuals)<br>
                                predictions[i] = loess_model.predict(X_scaled[i].reshape(1, -1))<br>
                            residuals -= predictions<br>
                            self.models.append(model)<br>
                        self.is_fitted_ = True<br>
                    <br>
                    def predict(self, X):<br>
                        X_scaled = self.scaler.transform(X)<br>
                        final_predictions = np.zeros(len(X_scaled))<br>
                        for model in self.models:<br>
                            step_predictions = np.zeros(len(X_scaled))<br>
                            for i in range(len(X_scaled)):<br>
                                step_predictions[i] = model.predict(X_scaled[i].reshape(1, -1))<br>
                            final_predictions += step_predictions<br>
                        return final_predictions / len(self.models)<br>
                    <br>
                    def is_fitted(self):<br>
                        return self.is_fitted_<br>
                    <br>
                    def cross_validate(self, X, y, n_splits=10):<br>
                        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)<br>
                        mse_scores = []<br>
                        for train_index, val_index in kf.split(X):<br>
                            X_train, X_val = X[train_index], X[val_index]<br>
                            y_train, y_val = y[train_index], y[val_index]<br>
                            self.fit(X_train, y_train, boosting_steps=10)<br>
                            y_pred = self.predict(X_val)<br>
                            mse = mean_squared_error(y_val, y_pred)<br>
                            mse_scores.append(mse)<br>
                        return np.mean(mse_scores)
            </code>
        </div>

        <p>Gradient boosting is applied in the <code>fit</code> and <code>predict</code> methods. The method <code>fit</code> applies the loss function, and the residuals of the model represent how far away the predictions are from the true y values. The function performs this for <code>boosting_steps</code> number of iterations, which is optimized later in the code.</p>

        <h2>Scaler Testing</h2>
        <p>Below is the code for testing which scalar has the best MSE out of <code>StandardScaler</code>, <code>MinMaxScaler</code>, and <code>QuantileTransformer</code>.</p>

        <div class="code-block">
            <code>
                scalers = [StandardScaler(), MinMaxScaler(), QuantileTransformer()]<br>
                mse_scalers = []<br>
                for scaler in scalers:<br>
                    loess_model = LOESS(kern=Quartic, tau=0.05, alpha=0.01, scalerType=scaler)<br>
                    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)<br>
                    loess_model.fit(X_train, y_train, boosting_steps=10)<br>
                    predictions = loess_model.predict(X_test)<br>
                    mse = mean_squared_error(y_test, predictions)<br>
                    mse_scalers.append(mse)
            </code>
        </div>

        <p>StandardScaler had an MSE of 1502.299, MinMaxScaler an MSE of 1299.467, and QuantileTransformer an MSE of 1311.889. Therefore, the best scaler to use on the concrete dataset is <code>MinMaxScaler</code>.</p>

        <h2>Kernel Testing</h2>
        <p>The code below tests for the best kernel out of Gaussian, Tricubic, Epanechnikov, and Quartic.</p>

        <div class="code-block">
            <code>
                kernels = [Gaussian, tricubic, Epanechnikov, Quartic]<br>
                mse_kernel = []<br>
                for kernel in kernels:<br>
                    loess_model = LOESS(kern=kernel, tau=0.05, alpha=0.01, scalerType=MinMaxScaler())<br>
                    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)<br>
                    loess_model.fit(X_train, y_train, boosting_steps=10)<br>
                    predictions = loess_model.predict(X_test)<br>
                    mse = mean_squared_error(y_test, predictions)<br>
                    mse_kernel.append(mse)
            </code>
        </div>

       <p>Interestingly, the kernel did not matter as much as the scalar did, as all the MSE values had the same value at 1299.467, the same as the MSE from just testing the <code>MinMaxScaler</code>. Further research is required to find out why this is, as the kernel should generally change the outcome. Normally, the <code>Epanechnikov</code> kernel would yield the lowest MSE out of all the kernels.</p>

        <h2>Hyperparameter Testing</h2>
        <p>The code below shows the testing steps to determine the best hyperparameters. Here, I tested for the optimal number of boosting steps, tau, and alpha. The steps I chose were from 5-10, for tau 0.05-0.1, and for alpha 0.01 to 0.1. I did not want to include a huge range for any of these hyperparameters because the execution time was increasing exponentially. This was the best range I found that would execute in a timely manner while also covering a wide range of hyperparameters.</p>

        <div class="code-block">
            <code>
                best_n_steps = None<br>
                best_tau = None<br>
                best_alpha = None<br>
                best_mse = float('inf')<br>
                <br>
                for n_steps in [5, 10]:<br>
                    for tau in [0.05, 0.1]:<br>
                        for alpha in [0.01, 0.1]:<br>
                            loess_boost_model = LOESS(kern='tricube', tau=tau, alpha=alpha, scalerType=MinMaxScaler())<br>
                            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)<br>
                            loess_model.fit(X_train, y_train, boosting_steps=n_steps)<br>
                            <br>
                            predictions = loess_model.predict(X_test)<br>
                            <br>
                            mse = mean_squared_error(y_test, predictions)<br>
                            if mse < best_mse:<br>
                                best_mse = mse<br>
                                best_n_steps = n_steps<br>
                                best_tau = tau<br>
                                best_alpha = alpha
            </code>
        </div>

        <p>At the end of these processes, I determined that the best parameters to be used in the gradient boosting algorithm were 5 steps of boosting, a tau of 0.1, and an alpha of 0.1. This yielded the best MSE of 1158.985. Finally, the best model after all of the testing is shown here:</p>

        <div class="code-block">
            <code>
                loess_model = LOESS(kern=Gaussian, tau=0.1, alpha=0.1, scalerType=MinMaxScaler())
            </code>
        </div>

        <h2>Final Cross Validation</h2>
        <p>After testing it in a 10-split cross validation, the final MSE is 1361.708.</p>

        <h2>Comparison with eXtreme Gradient Boosting</h2>
        <p>Compared to the eXtreme Gradient Boosting (XGBoost), the MSE is significantly higher. The eXtreme model ended with an MSE of 23.730, which is magnitudes lower than my self-implemented gradient boosting and LOESS algorithm. Clearly, there is a critical error within my implementation, but I was not able to determine where this is.</p>

               <h1>Homework 2 - Question 2</h1>

        <h2>Iris Dataset Classification</h2>
        <p>Using the <em>iris</em> dataset, which contains 4 feature variables describing the physical characteristics of irises, I implemented locally weighted logistic regression to classify which species of flower they belonged to based on these features. Below is my implementation of locally weighted logistic regression:</p>

        <div class="code-block">
            <code>
                def lwlr(X, y, x_query, tau):<br>
                    m = len(y)<br>
                    weights = np.array([kernel(x_query, X[i], tau) for i in range(m)])<br>
                    W = np.diag(weights)<br>
                    <br>
                    theta = np.linalg.pinv(X.T @ W @ X) @ X.T @ W @ y<br>
                    return expit(x_query @ theta)
            </code>
        </div>

        <p>To accommodate all possible classifications in this multiclass dataset (which contains 3 possible categories), I used a one-vs-all approach. This means that for each category, the algorithm performs binary classification: 1 vs not 1, 2 vs not 2, or 3 vs not 3.</p>

        <div class="code-block">
            <code>
                def predict_multiclass_lwlr(X, y, X_query, tau):<br>
                    n_classes = len(np.unique(y))<br>
                    predictions = []<br>
                    <br>
                    for c in range(n_classes):<br>
                        binary_y = np.where(y == c, 1, 0)<br>
                        class_preds = [lwlr(X, binary_y, x_query, tau) for x_query in X_query]<br>
                        predictions.append(class_preds)<br>
                    <br>
                    predictions = np.array(predictions).T<br>
                    return np.argmax(predictions, axis=1)
            </code>
        </div>

        <p>Testing this implementation on the <em>iris</em> dataset yielded an accuracy of 81.33%. The one-vs-all approach worked effectively for this multiclass problem.</p>

        <h2>One-vs-All Classification</h2>
        <p>As noted, this dataset contains 3 categories, so the one-vs-all method converts the multiclass problem into multiple binary classification problems. Each classifier predicts whether a sample belongs to one specific class or not.</p>

        <h2>Comparison with Calvin Chi’s Algorithm</h2>
        <p>Using Calvin Chi’s algorithm with a similar one-vs-all approach also resulted in an accuracy of 81.33%. Both implementations produced the same result. Below is a visualization of how these algorithms categorized the data. The colored dots represent the true class labels, while the colored sections indicate the algorithm's predictions.</p>
        <p><img src="images/graph2.PNG" alt="Graph of locally weighted logistic regression"></p>

 <h1>Homework 3</h1>
        <h2>Question 1: SCAD Algorithm</h2>
        <p>SCAD stands for smoothly clipped absolute deviation. This algorithm is a regularization and variable selection algorithm, most similar to other algorithms such as LASSO and ElasticNet. The benefit of using SCAD is that it alleviates the bias which affects algorithms like LASSO. Using the SCAD penalty and derivative function found on Andy Jones’ implementation below, I modified previous code used for ElasticNet and adapted it to use the SCAD algorithm.</p>

        <div class="code-block">
            <code>
                # Modified for usage with torch<br>
                def scad_penalty(beta_hat, lambda_val, a_val):<br>
                    is_linear = (torch.abs(beta_hat) <= lambda_val)<br>
                    is_quadratic = (lambda_val < torch.abs(beta_hat)) & (torch.abs(beta_hat) <= a_val * lambda_val)<br>
                    is_constant = (a_val * lambda_val) < torch.abs(beta_hat)<br>
                    <br>
                    linear_part = lambda_val * torch.abs(beta_hat) * is_linear<br>
                    quadratic_part = (2 * a_val * lambda_val * torch.abs(beta_hat) - beta_hat**2 - lambda_val**2) / (2 * (a_val - 1)) * is_quadratic<br>
                    constant_part = (lambda_val**2 * (a_val + 1)) / 2 * is_constant<br>
                    return linear_part + quadratic_part + constant_part<br>
                <br>
                def scad_derivative(beta_hat, lambda_val, a_val):<br>
                    return lambda_val * ((beta_hat <= lambda_val) + (a_val * lambda_val - beta_hat) * ((a_val * lambda_val - beta_hat) > 0) / ((a_val - 1) * lambda_val) * (beta_hat > lambda_val))
            </code>
        </div>

        <p>These methods are then used to calculate the penalty when training the SCAD model. Below is the modified SCAD model that integrates the penalty into the loss function.</p>

        <div class="code-block">
            <code>
                class SCAD(nn.Module):<br>
                    def __init__(self, input_size, alpha=1.0, lambda_val=0.1, a_val=0.5):<br>
                        super(SCAD, self).__init__()<br>
                        self.input_size = input_size<br>
                        self.alpha = alpha<br>
                        self.a_val = a_val<br>
                        self.lambda_val = lambda_val<br>
                        self.linear = nn.Linear(input_size, 1, dtype=torch.float64)<br>
                    <br>
                    def forward(self, x):<br>
                        return self.linear(x)<br>
                    <br>
                    def loss(self, y_pred, y_true):<br>
                        mse_loss = nn.MSELoss()(y_pred, y_true)<br>
                        scad_reg = scad_penalty(self.linear.weight, self.lambda_val, self.a_val).sum()<br>
                        loss = mse_loss + self.alpha * scad_reg<br>
                        return loss<br>
                    <br>
                    def fit(self, X, y, num_epochs=100, learning_rate=0.01):<br>
                        optimizer = optim.SGD(self.parameters(), lr=learning_rate)<br>
                        for epoch in range(num_epochs):<br>
                            self.train()<br>
                            optimizer.zero_grad()<br>
                            y_pred = self(X)<br>
                            loss = self.loss(y_pred, y)<br>
                            loss.backward()<br>
                            optimizer.step()<br>
                            if (epoch + 1) % 10 == 0:<br>
                                print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}")<br>
                    <br>
                    def predict(self, X):<br>
                        self.eval()<br>
                        with torch.no_grad():<br>
                            y_pred = self(X)<br>
                        return y_pred<br>
                    <br>
                    def get_coefficients(self):<br>
                        return self.linear.weight
            </code>
        </div>

        <p>Using the concrete dataset, I trained a SCAD model on a train-test split of the data, with the final test loss at 102.4876. After training the model, I obtained the learned weights to determine which features were useful. The closer a feature's coefficient is to 0, the less important it is.</p>

        <h2>Feature Importance</h2>
        <p>The feature with the lowest importance was the amount of ash in the concrete, with a weight of -0.1623.</p>

        <h2>Question 2: Testing Algorithms on Simulated Data</h2>
        <p>Using the code to generate simulated data from the lecture, I tested the three algorithms: ElasticNet, square root LASSO, and my SCAD implementation. Below is the function to generate correlated features:</p>

        <div class="code-block">
            <code>
                def make_correlated_features(num_samples, p, rho):<br>
                    vcor = []<br>
                    for i in range(p):<br>
                        vcor.append(rho**i)<br>
                    r = toeplitz(vcor)<br>
                    mu = np.repeat(0, p)<br>
                    x = np.random.multivariate_normal(mu, r, size=num_samples)<br>
                    return x
            </code>
        </div>

        <p>The final results were:</p>
        <ul>
            <li>ElasticNet MSE: 1.0150</li>
            <li>Square Root LASSO MSE: 1.0439</li>
            <li>SCAD MSE: 0.6941</li>
        </ul>
        <p>The SCAD algorithm had the lowest MSE and therefore performed the best on this simulated dataset.</p>

        <h2>Question 3: Cross Validation</h2>
        <p>To determine the best weights for the penalty function and cross-validate the results, I created a modified version of a previous cross-validation function to work with tensors and include a model parameter.</p>

        <div class="code-block">
            <code>
                def cross_validate_model(model_class, X_tensor, y_tensor, alpha_vals, num_epochs=100, learning_rate=0.01, k_folds=5):<br>
                    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)<br>
                    best_alpha = None<br>
                    best_mse = float('inf')<br>
                    for alpha in alpha_vals:<br>
                        fold_mses = []<br>
                        for train_idx, val_idx in kf.split(X_tensor):<br>
                            X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]<br>
                            y_train, y_val = y_tensor[train_idx], y_tensor[val_idx]<br>
                            model = model_class(input_size=X_train.shape[1], alpha=alpha)<br>
                            model.fit(X_train, y_train, num_epochs=num_epochs)<br>
                            y_pred = model.predict(X_val)<br>
                            mse = nn.MSELoss()(y_pred, y_val).item()<br>
                            fold_mses.append(mse)<br>
                        mean_mse = np.mean(fold_mses)<br>
                        if mean_mse < best_mse:<br>
                            best_mse = mean_mse<br>
                            best_alpha = alpha<br>
                    return best_alpha, best_mse
            </code>
        </div>
        <p>Using this method, I tested the three models to determine the best weights and evaluated the best weights and used that model to find the ideal model size. The results were similar to the previous question, with square root lasso resulting in a best cross validated mse of 3.1084, with the best alpha being 0.0215. The cross validated mse for ElasticNet was 1.8336, the best alpha was 0.0599. The best model was SCAD, with a cross validated mse of 1.8198 and the best alpha was 0.1668. Using this alpha and the SCAD algorithm on the concrete dataset, the best model was a model excluding the ash feature variable, as its weight was only 0.0881 which is very close to 0. So the best model would use the SCAD weights for cement, slag, water, superplastic, coarseagg, fineagg, and the age feature variables.</p>
<h1>Homework 4 - Porto Seguro Safe Driver Prediction</h1>

<p>The Porto Seguro Safe Driver Prediction is an example of an unbalanced dataset. This type of dataset is binary, with two distinct target classes of 0 and 1, where one class dominates the other in terms of the number of data points proportionally. For this dataset, there are only 2 classes: 0 or 1. As seen below, class 0 contains 573,518 data points, while class 1 contains 21,694. This is a proportion of about 26.44 to 1.</p>

<img src="path/to/image/count_raw.png" alt="Class Count Raw Data">

<p>Upon testing this dataset using a logistic regression model, it yields satisfactory results on the surface, with an accuracy of 96.36%. However, upon closer inspection, the regression model completely neglects the minority class (class 1). To understand this better, we use a confusion matrix. As shown below, the model labels all cases as class 0, and because the vast majority of data points are class 0, this yields a high accuracy score. Evidently, this is not exactly what we want, so we will use methods such as Synthetic Minority Oversampling (SMOTE), ADASYN, and Normalizing Flows to oversample the minority class.</p>

<img src="path/to/image/confusion_sample.png" alt="Confusion Matrix Sample">

<h2>Data Visualization and Model Testing Methods</h2>
<p>These are the methods used to visualize and test on the data. We are using a Logistic Regression model due to its simplicity. Our goal is to test the effectiveness of the data generating algorithms, not the learning model itself.</p>

<pre><code>
def plot_count(data):
    target_count = data.target.value_counts()
    print('Class 0:', target_count[0])
    print('Class 1:', target_count[1])
    print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')

    target_count.plot(kind='bar', title='Count (target)');
</code></pre>

<pre><code>
def test_acc(X, y):
    x_scaled = StandardScaler().fit_transform(X)
    model = linear_model.LogisticRegression()
    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)
    lst_accu_stratified = []
    y_pred_all = []

    for train_index, test_index in skf.split(X, y):
        x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]
        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]
        model.fit(x_train_fold, y_train_fold)
        lst_accu_stratified.append(model.score(x_test_fold, y_test_fold))
        y_pred = model.predict(x_test_fold)
        y_pred_all.extend(y_pred)

    print('Average Accuracy', np.mean(lst_accu_stratified))

    return y_pred_all
</code></pre>

<pre><code>
def plot_confusion(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,5))
    sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r')
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')
</code></pre>

<h2>Data Sampling and Stratification</h2>
<p>Before starting, this dataset contains a large amount of variables, so for expediency, we only use 10% of the data. By using stratified k-fold, we can keep the same proportion of class 0 to class 1.</p>

<img src="images/count_sample.png" alt="Count Sample Data">

<h2>SMOTE Algorithm</h2>
<p>Using the SMOTE algorithm, a preprocessing algorithm that creates artificial data points for the minority class, we can balance out class 1 and 0 to an even proportion of 1:1. We get an average accuracy of 92.59% across a stratified 10-fold cross validation. Below is the confusion matrix.</p>

<img src="images/count_smote.png" alt="Count after SMOTE">
<img src="images/confusion_smote.png" alt="Confusion Matrix after SMOTE">

<h2>ADASYN Algorithm</h2>
<p>Using the ADASYN algorithm, which creates synthetic samples based on the feature space of the original data, we again balance out the classes to a 1:1 proportion. We get an average accuracy of 92.67% across a stratified 10-fold cross validation, slightly more accurate than the SMOTE algorithm.</p>

<img src="images/count_adasyn.png" alt="Count after ADASYN">
<img src="images/confusion_adasyn.png" alt="Confusion Matrix after ADASYN">

<h2>Kernel Density Estimation (KDE)</h2>
<p>There is also a technique called fastKDE (kernel density estimation), which is a function that estimates the probability density function (pdf) of a data sample. This is useful for gaining a high-level understanding of a data sample’s distribution. However, this algorithm is affected by the Curse of Dimensionality and struggles with higher-dimensional data, so we use PCA to reduce the number of feature variables.</p>

<pre><code>
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(Xs)
X_reduced
</code></pre>

<p>Below is a graph depicting the KDE on a PCA-reduced dataset. Here, it is easy to see that data falls into “baskets” of high concentrations of similar data points. This is due to the nature of the original dataset, which contains 58 feature variables of ordinal numbers, and the effect of combining all of these variables into just 2 feature variables using PCA.</p>

<img src="images/kde.png" alt="Kernel Density Estimation after PCA">

<h2>Normalizing Flows</h2>
<p>Finally, we can use normalizing flows to oversample the minority class, a technique that transforms simple probabilistic problems into more complex problems through a series of invertible and differentiable mappings. The code for this process is adapted from Professor Vasiliu’s GitHub, with some modifications to adapt to the dataset. Below, I am applying the transformation:</p>

<pre><code>
device = torch.device('cuda')

num_features = 58
num_layers = 5
base_dist = ConditionalDiagonalNormal(shape=[num_features], context_encoder=nn.Linear(1, 2 * num_features))

transforms = []
for i in range(num_layers):
    transforms.append(ReversePermutation(features=num_features))
    transforms.append(MaskedAffineAutoregressiveTransform(features=num_features,
                                                          hidden_features= 4 * num_features,
                                                          context_features=1))
transform = CompositeTransform(transforms)

flow = Flow(transform, base_dist).to(device)
optimizer = optim.Adam(flow.parameters())
</code></pre>

<p>Here, I am training the model using the log probabilities. We are using tensors here instead of np.arrays. I chose a range of 10,000 iterations because this algorithm is computationally expensive, and 10,000 strikes a balance between computational time and model accuracy.</p>

<pre><code>
for i in range(10000):
    X = train_sample.drop('target', axis=1).values
    y = train_sample['target'].values
    X = torch.tensor(X, dtype=torch.float32, device=device)
    y = torch.tensor(y, dtype=torch.float32, device=device).reshape(-1, 1)
    optimizer.zero_grad()
    loss = -flow.log_prob(inputs=X, context=y).mean()
    loss.backward()
    optimizer.step()
</code></pre>

<p>Using more of the code from Professor Vasiliu’s Normalizing Flow examples, we found the final prediction accuracy to be 96.36%, the highest among the minority oversampling algorithms.</p>

</body>
</html>
